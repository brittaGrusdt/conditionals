// Parameters
// var thresholds = {t: 0.899, f: 0.0499, theta: 0.899, theta_likely : 0.499}
globalStore.thresholds = {t: 0.899, f: 0.0499, theta: data["theta"][0], theta_likely : 0.499}

// states + utterances
globalStore.cns = data["cns"]
globalStore.utterances = data["utterances"]

var tables_list = data["tables"]
globalStore.Tables = map(function(obj){
  var p = Categorical({"vs": obj["vs"], "ps": obj["ps"]})
  return {"id": obj["stimulus_id"], "Table": p}
}, tables_list)

// model parameters
globalStore.alpha = data["alpha"][0]
globalStore.cost_conditional = data["cost_conditional"][0]
globalStore.speaker_intents = data["speaker_intents"]
// globalStore.speaker_intents = ["ISA", "PA"]

// var degree = data["degree"][0]
var BIAS = data["bias"][0]
globalStore.bias = BIAS
if(globalStore.bias == "judy"){
  globalStore.judy_q = data["judy_q"][0]
}
var UTT = data["utt"][0]

// parameter for likelihood functions
globalStore.indep_sigma = data["indep_sigma"][0]

// output parameters
var LEVEL_MAX = data["level_max"][0]
var verbose = data["verbose"][0]

if(verbose){
  display('# utterances:' + (globalStore.utterances).length)
  display("utterance for listeners: " + UTT)
  display("cost conditional:" + globalStore.cost_conditional)
  display("# cns:" + (globalStore.cns).length)
  display("bias: " + BIAS)
  display("alpha:" + globalStore.alpha)
  display("# tables:" + tables_list.length)
  display("speaker intentions: " + globalStore.speaker_intents)
  BIAS == "judy" ? display('judy q: ' + globalStore.judy_q) : ''
}

// Run from R ----------------------------------------------------------------
var run = function(level){
  if(verbose){ display("run " + level + " ...") }
  return level == "prior" ? state_prior(BIAS) :
         level == "LL" ? literal_listener(UTT, BIAS) : listener(UTT, BIAS)
}

globalStore.state_prior = run("prior")
var all_bns = map(function(obj){obj["bn"]}, (globalStore.state_prior).support())
if(verbose){display('# states: ' + all_bns.length)}
// display('single bn: ')
// display(all_bns[0])

var wrap_speaker = function(bn, intention){
  var state = {bn, intention}
  speaker(state, BIAS, false)
}

var wrap_ll = function(u){
  display(u)
  literal_listener(u, BIAS)
}

var run_speaker = function(bns){
  if(globalStore.speaker_intents.indexOf("ISA") != -1 &&
     globalStore.speaker_intents.indexOf("PA") != -1){
       var isa = map(function(bn){wrap_speaker(bn, "ISA")}, bns)
       var pa = map(function(bn){wrap_speaker(bn, "PA")}, bns)

       var distributions = {"speaker_isa": isa, "speaker_pa": pa, "bns": bns}
       distributions
     } else{
       var distrs = map(function(bn){wrap_speaker(bn, "")}, bns)
       var distributions = {"speaker_": distrs, "bns": bns}
       distributions
     }
}


// RUN MODEL
if(LEVEL_MAX == "speaker"){
  // run speaker with only bayes nets for which meaning of UTT is true
  // use (UTT="" for all)
  // 1. sample n_samples bayes  nets from prior or
  var n_samples = data["n_samples"][0]
  if(n_samples != 0){
    var prior_conditioned = Infer({model:function(){

      var state = sample(globalStore.state_prior)
      var Table = state["bn"]["table"]

      //1. UTT is applicable in current state
      // condition(meaning(UTT, Table))

      // 2. when C is true, but not A and C, and not -A and C
      // var meaning_ac = meaning("A and C", Table)
      // var meaning_nac = meaning("-A and C", Table)
      // condition(!meaning_ac && !meaning_nac)

      // 3. Assertability conditions
      // p_rooij/p_delta larger than a threshold
      let pac = Math.exp(Table.score("AC"))
      let pnac = Math.exp(Table.score("-AC"))
      let pa = pac + Math.exp(Table.score("A-C"))
      let p_c_given_a = pac / pa
      let p_c_given_na = pnac / (1-pa)
      let p_delta = p_c_given_a - p_c_given_na
      let p_rooij = p_delta / (1 - p_c_given_na)

      if(UTT == "p_rooij"){
        condition(p_rooij >= 0.75)
      } else if (UTT == "p_delta"){
        condition(p_delta > 0 && p_c_given_a >= 0.75)
      }
      return state.bn
    }})
    var bns = repeat(n_samples, function(){sample(prior_conditioned)})
    display('# samples from prior: ' + bns.length)
    // var distrs_isa = map(function(bn){wrap_speaker(bn, "ISA")}, bns)
    // var distrs_pa = map(function(bn){wrap_speaker(bn, "PA")}, bns)
    //
    // var distributions = {"speaker_isa": distrs_isa, "speaker_pa": distrs_pa,
    //                      "bns": bns}
    var distributions = run_speaker(bns)
    distributions

  } else{
    // 2. run speaker with all bayes nets in prior (use n_samples=0)
    // display('# all input bns: ' + all_bns.length)
    var bns = filter(function(bn){meaning(UTT, bn.table)}, all_bns)
    // display('# used bns (where utt is true): ' + bns.length)
    var distributions = run_speaker(bns)
    distributions
  }
} else if(LEVEL_MAX == "ll_all_utts"){
  var distributions = {"ll": map(wrap_ll, globalStore.utterances)}
  distributions

} else if(LEVEL_MAX == "prior_conditioned"){
  var distributions = map(function(cn){
                        display(cn)
                        Infer({model:function(){
                          var s = sample(globalStore.state_prior)
                          condition(s["bn"]["cn"] == cn)
                          return s
                        }})
                      }, globalStore.cns)

  var obj = {distributions}
  obj

} else{
  var distributions = LEVEL_MAX == "prior" ? {"prior": globalStore.state_prior} :
                      LEVEL_MAX == "LL" ? {"prior": globalStore.state_prior, "LL": run("LL")} :
                      LEVEL_MAX == "PL" ? {"prior": globalStore.state_prior, "LL": run("LL"),
                                           "PL": run("PL")} :
                      error("unknown output level: " + LEVEL_MAX)

  // object to return to R
  distributions
}
