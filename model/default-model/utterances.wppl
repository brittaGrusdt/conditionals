// var data = {
//   "verbose": [true],
//   "vars": ["A", "C"],
//   "bias": ["none"]
//   "tables": //add example here
// }
globalStore.thresholds = {t: 0.899, f: 0.0499, theta: data["theta"][0], theta_likely : 0.499}

var verbose = data["verbose"][0]
var variables = data["vars"]
var bias = data["bias"][0]
globalStore.bias = bias
if(globalStore.bias == "judy"){
  globalStore.judy_q = data["judy_q"][0]
}
var tables_list = data["tables"]

globalStore.Tables = map(function(obj){
  return {"id": obj["stimulus_id"], "Table": Categorical({"vs": obj["vs"], "ps": obj["ps"]})}
}, tables_list)

globalStore.speaker_intents = data["speaker_intents"]
globalStore.indep_sigma = data["indep_sigma"][0]

if(verbose){
  display("bias: " + bias)
  display("theta: " + globalStore.thresholds.theta)
  display("# tables: " + globalStore.Tables.length)
  display("vars: " + variables)
}

var variables = reduce(function(token, acc){
  acc.concat([[token, negate(token)]])
}, [], variables)

var powerset = get_var_powerset(variables, false)
var dependent_nets = connect_variables(powerset, " implies ")
globalStore.cns = dependent_nets.concat("A || C")

if(verbose){
  display('# cns: ' + globalStore.cns.length)
}

var utterances = make_utterances(powerset)
if(verbose){
  display("all utterances:")
  map(display, utterances)
  display('# all utterances: ' + utterances.length)
}

var all_states = state_prior(bias).support()
if(verbose){
  display('# states: ' + all_states.length)
}

var utts_to_remove = filter(function(u){
  !any(function(s){meaning(u, s["bn"]["table"])}, all_states)
}, utterances)

if(verbose){
  display('# utts without corresponding state: ' + utts_to_remove.length)
  display("removed utterances:")
  map(display, utts_to_remove)
}

var utterances = filter(function(u){utts_to_remove.indexOf(u) == -1}, utterances)
if(verbose){
  display("included utterances:")
  map(display, utterances)
  display('# included utterances: ' + utterances.length)
}

utterances
