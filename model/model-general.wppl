// Parameters ----------------------------------------------------------------
globalStore.thetaCP = 0.05
var thresholds = {t: 0.899, f: 0.0499, theta: 0.899, theta_maybe : 0.499}
var verbose = data["verbose"][0]
var tables_list = data["tables"]
var noise_v = data["noise_v"][0]
var ALPHA = data["alpha"][0]
var UTTERANCES = data["utterances"]
var CAUSAL_NETS = data["cns"]
var LEVEL_MAX = data["level_max"][0]
var COST_CONDITIONAL = data["cost_conditional"][0]
var UTT = data["utt"][0]
var BIAS = data["bias"][0]

var vars = [["A", "-A"], ["C", "-C"]]
var p_ac_ind = {"none": 0.15,
                "lawn": 0.1,
                "pizza" : 1,
                "BC-impossible-cons": 1
                }
if(verbose){
  display("")
  display('# utterances:' + UTTERANCES.length)
  display("utterance for listeners: " + UTT)
  display("bias: " + BIAS)
  display("")
}

var params_noise_ind = {
  250 : [1, 132]
}
var params_ind = params_noise_ind[noise_v]

var tables = map(function(obj){
  Categorical({"vs": obj["vs"], "ps": obj["ps"]})
}, tables_list)
if(verbose){
  display('# tables: ' + tables.length)
  display('beta param for independent likelihood: ' + params_ind)
}

// Helper --------------------------------------------------------------------
var intersect_arrays = cache(function(arrays){
  return filter(function(m){
          var m_in_all_lists = map(function(idx){arrays[idx].includes(m)},
                                  _.range(1,arrays.length))
          return sum(m_in_all_lists)==m_in_all_lists.length
    }, arrays[0])
},10000)

// Probabilities ------------------------------------------------------------
var marginal = cache(function(table, variables){
  // computes the probability of P(A) marginalized over all other variables in
  // support of table with P=table and variables=["A"]
  var tokens = table.support()
  var all_x = map(function(v){
    v.includes("-") ? filter(function(k){k.includes(v)}, tokens) :
                      filter(function(k){!k.includes("-"+v)}, tokens)
  }, variables)
  var xs = intersect_arrays(all_x)

  return reduce(function(x, acc){acc + Math.exp(table.score(x))}, 0, xs)
})

var conditional_probs = cache(function(table){
  return {"P(C|A)" : marginal(table, ["A", "C"]) / marginal(table, ["A"]),
          "P(C|-A)": marginal(table, ["-A", "C"]) / marginal(table, ["-A"]),
          "P(A|C)" : marginal(table, ["A", "C"]) / marginal(table, ["C"]),
          "P(A|-C)": marginal(table, ["A", "-C"]) / marginal(table, ["-C"])}
}, 10000)

var value_approx_likelihood = cache(function(table){
    Math.abs(marginal(table, ["A", "C"]) - (marginal(table, ["C"]) *
                                            marginal(table, ["A"])))
  }, 10000)

var cn_to_prob = cache(function(state){
  var cn = state.cn
  var table = state.table
  var probs = conditional_probs(table)
  return cn == "A implies C" ? [probs["P(C|A)"], probs["P(C|-A)"]] :
         cn == "A implies -C" ? [1 - probs["P(C|A)"], 1 - probs["P(C|-A)"]] :
         cn == "-A implies C" ? [probs["P(C|-A)"], probs["P(C|A)"]] :
         cn == "-A implies -C" ? [1 - probs["P(C|-A)"], 1 - probs["P(C|A)"]] :
         cn == "C implies A" ? [probs["P(A|C)"], probs["P(A|-C)"]] :
         cn == "C implies -A" ? [1 - probs["P(A|C)"], 1 - probs["P(A|-C)"]] :
         cn == "-C implies A" ? [probs["P(A|-C)"], probs["P(A|C)"]] :
         cn == "-C implies -A" ? [1 - probs["P(A|-C)"], 1 - probs["P(A|C)"]] :
         cn == "A || C" ? value_approx_likelihood(table) :
  error('unknown network: ' + cn)
}, 10000)

// State prior  --------------------------------------------------------------
var cn_prior = function(bias) {
  var p_ind = p_ac_ind[bias]
  var p_dep = (1 - p_ind) / (CAUSAL_NETS.length-1)
  // var p_ind = 1 / CAUSAL_NETS.length
  // var p_dep = 1 / CAUSAL_NETS.length
  var ps = map(function(cn){cn=="A || C" ?  p_ind : p_dep}, CAUSAL_NETS)
  return categorical({vs: CAUSAL_NETS, ps: ps})
}

var log_likelihood = function(state){
  var p = cn_to_prob(state)
  return state.cn == "A || C" ?
          Beta({a:params_ind[0], b: params_ind[1]}).score(p) :
          (Beta({a:10, b:1}).score(p[0])+Beta({a:1, b:10}).score(p[1]))
}

var state_prior = cache(function(bias){
  return Infer({method:'enumerate', model:function(){
    var state = {"table": uniformDraw(tables),
                 "cn": cn_prior(bias)}
    var strength = log_likelihood(state)
    factor(strength)

    if(bias=='lawn'){
      if(Math.exp(state.table.score("-AC")) <= globalStore.thetaCP){
        factor(-Math.log(thresholds.f))
      }
    }else if(bias == "BC-impossible-cons"){
      condition(marginal(state.table, ["C"]) <= thresholds.f)
    }
    return state
  }})
})

// Meaning ------------------------------------------------------------------
var utterance_probs = cache(function(utterance, table){
  if(utterance.includes(">")){
    var components = utterance.split(" > ")
    var antecedent = components[0].split(" and ").join("")
    var consequent = components[1].split(" and ").join("")
    return marginal(table, [antecedent, consequent]) /
           marginal(table, [antecedent])
  }
  else if(utterance.includes("maybe")){
    var u = utterance.slice("maybe ".length)
    return marginal(table, [u])
  }
  else if(utterance.includes("and")){
    var components = utterance.split(" and ")
    return marginal(table, components)
  }
  else {
    return marginal(table, [utterance])
  }
})

var meaning = cache(function(utterance, table){
 var p = utterance_probs(utterance, table)
 var u_applicable = utterance.includes('maybe') ?
     (p >= thresholds.theta_maybe) : p >= thresholds.theta
 return u_applicable
})

// Model ---------------------------------------------------------------------
var literal_listener = cache(function(utterance, bias){
  Infer({method:'enumerate',model: function(){
    var state = sample(state_prior(bias))
    condition(meaning(utterance, state.table))
    return state
  }})
}, 10000)

var costs = cache(function(utt){
  if(!UTTERANCES.includes(utt)){error('unknown utterance ' + utt)}
  var c1 = utt.includes(' > ') ? COST_CONDITIONAL : 0
  var c2 = (utt.split(' and ').length - 1) * (COST_CONDITIONAL/2)
  var c3 = utt.split('-').length > 1 ?  (COST_CONDITIONAL/4) : 0
  var c4 = utt.includes('maybe') ? (COST_CONDITIONAL/5) : 0
  return c1 + c2 + c3 + c4
}, 10000)

var speaker = cache(function(bn, bias, displayU){
  return Infer({method:'enumerate', model: function(){
    var utterance = uniformDraw(UTTERANCES)
    var LL = literal_listener(utterance, bias)
    var utility = LL.score(bn)
    // if(displayU && utility!=-Infinity){
    //   display(utterance + utility)
    // }
    factor(ALPHA * (utility - costs(utterance)))
    return utterance
  }
 })
}, 10000)

var listener = function(utterance, bias){
  return Infer({method:'enumerate', model:function(){
                  var bn = sample(state_prior(bias))
                  // factor(speaker(bn, bias, false).score(utterance))
                  observe(speaker(bn, bias, false),utterance)
                  return bn
                }})
}

// Run from R ----------------------------------------------------------------
var run = function(level){
  if(verbose){ display("run " + level + " ...") }
  return level == "prior" ? state_prior(BIAS) :
          level == "LL" ? literal_listener(UTT, BIAS) :
            listener(UTT, BIAS)
}

var prior = run("prior")
var all_states = prior.support()
if(verbose){display('# states: ' + all_states.length)}

var wrap_speaker = function(bn){
  speaker(bn, "none", false)
}

if(LEVEL_MAX == "speaker_all_bns"){
  var bns = filter(function(bn){
    meaning(UTT, bn.table)
  }, all_states)
  var distributions = {"speaker": map(wrap_speaker, bns)}
  distributions

} else if(LEVEL_MAX == "logLik"){

  var data = map(function(s){
      var logLik = log_likelihood(s)
      return {"logL": logLik, "cn": s.cn}
  }, all_states)

  var distributions = {"logLik": data}
  distributions

} else{
  var distributions = LEVEL_MAX == "prior" ? {prior} :
                      LEVEL_MAX == "LL" ? {"prior": prior, "LL": run("LL")} :
                      {"prior": prior, "LL": run("LL"), "PL": run("PL")}

  // object to return to R
  distributions
}
