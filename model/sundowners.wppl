// var data = {
//   "verbose": [true],
//   "utt": ["R > -S"],
//   "alpha": [5],
//   "cost_conditional": [0],
//   "prior_pr": [0.6, 0.7, 0.8]
// }
var thresholds = {theta: 0.899, theta_likely: 0.499}
var verbose = data["verbose"][0]
var LEVEL_MAX = data["level_max"] ? data["level_max"][0] : "PL"
var COST_CONDITIONAL = data["cost_conditional"][0]
var alpha = data["alpha"][0]
var prior_pr = data["prior_pr"]


if(verbose){
  display("alpha:" + alpha)
  display("cost conditional:" + COST_CONDITIONAL)
  display("prior P(R):" + prior_pr)
}

// Causal networks --------------------------------------------------------------
var causal_nets = {"cn1": "R > W > S", "cn2": "R||S"}
var prior_cn1 = 0.05
var prior_cn2 = 0.95
// Probabilities ----------------------------------------------------------------
var vars = [["R", "-R"], ["S", "-S"], ["W", "-W"]]
// var priors_rain = [0.1, 0.5, 0.9]
var priors_rain = prior_pr
var p_wedding_inside = {"R": 1, "-R": 0}
var probabilities = {"cn1": {"p_wi": p_wedding_inside,
                             "p_s": {"W": 0, "-W": 1}},
                     "cn2": {"p_wi": {"R": 1, "-R":1},
                             "p_s" : {"W": 1, "-W": 1}}
                    }
// Helper --------------------------------------------------------------------
var roundToN = function(x, n){
  var m = Math.pow(10,n)
  return Math.round(x*m)/m
}

var negate = function(x){
  return x.startsWith("-") ? x.slice(1) : "-" + x
}

var intersect_arrays = function(arrays){
  return filter(function(m){
          var m_in_all_lists = map(function(idx){arrays[idx].indexOf(m) != -1},
                                  _.range(1,arrays.length))
          return sum(m_in_all_lists)==m_in_all_lists.length
    }, arrays[0])
}

var combinations = Infer({model:function(){
  var bools = repeat(vars.length, flip)
  var tokens = mapIndexed(function(idx, b){
    b ? uniformDraw(vars[idx]) : ""
  }, bools)
  return filter(function(t){t.length>0}, tokens)
}}).support()
var combinations = filter(function(x){x.length > 0}, combinations)

var marginal = function(state, variables){
  var tokens = state.support()
  var all_x = map(function(v){
    v.indexOf("-") ? filter(function(k){k.indexOf(v) != -1}, tokens) :
                      filter(function(k){k.indexOf("-"+v) == -1}, tokens)
  }, variables)
  var xs = intersect_arrays(all_x)

  return reduce(function(x, acc){acc + Math.exp(state.score(x))}, 0, xs)
}

var combine_pairs = function(connective){
  var pairs_list = mapIndexed(function(idx, tokens1){
    var arr = filter(function(tokens){
      all(function(x){
        tokens.indexOf(x) == -1 && tokens.indexOf(negate(x)) == -1
      }, tokens1)
    }, combinations.slice(idx+1))

    var antecedent = tokens1.join(" and ")
    var ifs = map(function(tokens2){
      antecedent + connective + tokens2.join(" and ")
    }, arr)

    var ifs_rev = map(function(tokens2){
      tokens2.join(" and ") + connective + antecedent
    }, arr)
    return ifs.concat(ifs_rev)
  }, combinations)

  var pairs = reduce(function(arr, acc){
    acc.concat(arr)
  }, [], pairs_list)
  return pairs
}

// States ----------------------------------------------------------------
var joint_probs = function(token, cn, pr){
  var probs = probabilities[cn]
  var sw = token.indexOf("-W") != -1 ? probs["p_s"]["-W"] : probs["p_s"]["W"]
  var p_sw = token.indexOf("-S") != -1 ? 1-sw : sw

  var r = token.indexOf("-R") != -1 ? "-R" : "R"
  var wr = probs["p_wi"][r]
  var p_wr = token.indexOf("-W") != -1 ? 1-wr : wr

  var p_r = token.indexOf("-R") != -1 ? 1-pr : pr

  return p_sw * p_wr * p_r
}

var tokens = {"cn1": filter(function(tokens){tokens.length==3}, combinations),
              "cn2": filter(function(tokens){
                tokens.length==2 && tokens.indexOf("W") == -1
              }, combinations)}

var build_tables = cache(function(cn, p_r){
  var tokens_active = tokens[cn]
  var tokens_active_str = map(function(elems){elems.join("")}, tokens_active)

  return Infer({model:function(){
    var arr = map(function(elems){joint_probs(elems, cn, p_r)},
                  tokens_active_str)

    return categorical({vs:tokens_active_str, ps:arr})
  }})
})

var states = function(cn){
  var tables = map(function(p_rain){build_tables(cn, p_rain)}, priors_rain)
  var table = uniformDraw(tables)
  return {"cn": causal_nets[cn], "table": table}
}

var state_prior = Infer({model:function(){
  var cn = flip(prior_cn2) ? "cn2" : "cn1"
  return states(cn)
}})

// Utterances and meaning ----------------------------------------------------
var literals_conjunctions = map(function(tokens){
  tokens.join(" and ")
}, combinations)
display('# literals + # conjunctions: ' + literals_conjunctions.length)

var literals = filter(function(utt){utt.indexOf(" and ") == -1},
                      literals_conjunctions)
var utts_likely = map(function(utt){'likely ' + utt}, literals)
display('# utts_likely: ' + utts_likely.length)

var conditionals = combine_pairs(" > ")
display('# conditionals: ' + conditionals.length)

var utterances = literals_conjunctions.concat(conditionals.concat(utts_likely))
// map(display, utterances)
display('# utterances:' + utterances.length)

var utterance_probs = cache(function(utterance, state){
  if(conditionals.indexOf(utterance) != -1){
    var components = utterance.split(" > ")
    var antecedent = components[0].split(" and ").join("")
    var consequent = components[1].split(" and ").join("")
    return marginal(state, [antecedent, consequent]) /
           marginal(state, [antecedent])
  }
  if(literals.indexOf(utterance) != -1){return marginal(state, [utterance])}
  if(utts_likely.indexOf(utterance) != -1){
    var u = utterance.slice("likely ".length)
    return marginal(state, [u])
  }
  if(literals_conjunctions.indexOf(utterance) != -1){
    var components = utterance.split(" and ")
    return marginal(state, components)
  }
  else{error("unknown utterance " + utterance)}
  return p
})

var meaning = cache(function(utterance, state){
 var p = utterance_probs(utterance, state)
 var u_applicable = utterance.indexOf('likely') != -1 ?
     (p >= thresholds.theta_likely) : p >= thresholds.theta
 return u_applicable
})

var all_states = state_prior.support()

var utts_to_remove = filter(function(u){
  !any(function(s){meaning(u,s.table)}, all_states)
}, utterances)
display('# utts without corresponding state: ' + utts_to_remove.length)
// map(display, utts_to_remove)

var utterances = filter(function(u){utts_to_remove.indexOf(u) == -1}, utterances)
display('# included utterances: ' + utterances.length)
// map(display, utterances)

// Model ----------------------------------------------------------------------
var literal_listener = cache(function(utterance){
  Infer({method:'enumerate',model: function(){
    var state = sample(state_prior)
    condition(meaning(utterance, state["table"]))
    return state
  }})
}, 10000)

var cost = function(utt){
  if(utterances.indexOf(utt) == -1){error('unknown utterance ' + utt)}
  var c1 = utt.indexOf(' > ') != -1 ? COST_CONDITIONAL : 0
  var c2 = (utt.split(' and ').length - 1) * (COST_CONDITIONAL/2)
  var c3 = utt.split('-').length > 1 ?  (COST_CONDITIONAL/4) : 0
  var c4 = utt.indexOf('likely') != -1 ? (COST_CONDITIONAL/5) : 0
  return c1 + c2 + c3 + c4
}

var speaker = cache(function(state){
  var vars_in_support = state["table"].support()[0]
  return Infer({method:'enumerate', model: function(){
    var utterance = uniformDraw(utterances)
    var LL_score = literal_listener(utterance).score(state)
    var utility = LL_score == -Infinity ?
        LL_score : alpha * (LL_score-cost(utterance))

    factor(utility)
    return utterance
  }
 })
}, 10000)

var listener = function(utterance){
  return Infer({method:'enumerate', model:function(){
    var state = sample(state_prior)
                  observe(speaker(state), utterance)
                  return state
                }})
}

// Run from R ----------------------------------------------------------------
var u = data["utt"][0]
if(verbose){
  display("listener hears utterance: " + u)
}

var prior = state_prior
var ll = literal_listener(u)
var pl = listener(u)

var wrap_ll = function(u){
  var obj = {"u": u, "LL": literal_listener(u)}
  obj
}

if(LEVEL_MAX == "LL-all-utts"){
  var distributions = {"LL": map(wrap_ll, utterances)}
  distributions

} else {
  var distributions = {"PL": pl, "LL": ll, "prior": prior}
  distributions

}
