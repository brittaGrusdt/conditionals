// Parameters ----------------------------------------------------------------
var thresholds = {t: 0.899, f: 0.0499, theta: 0.899, theta_likely : 0.499}

// -------------- INPUT DATA -----------------------//
var CAUSAL_NETS = data["cns"]
var tables_list = data["tables"]

var TABLES = map(function(obj){
  Categorical({"vs": obj["vs"], "ps": obj["ps"]})
}, tables_list)

// model parameters
var BIAS = data["bias"][0]
// for bias lawn: max threshold for P(-A,C)
var threshold_cp = data["threshold_cp"] ? data["threshold_cp"][0] : 0.05

// parameter for likelihood functions
var SIGMA = data["indep_sigma"][0]
var PARAM_NOR_THETA = data["param_nor_theta"][0]
var PARAM_NOR_BETA = data["param_nor_beta"][0]

// output parameters
var verbose = data["verbose"][0]
// -------------- INPUT DATA -----------------------//

var vars = [["A", "-A"], ["C", "-C"]]
var p_ac_ind = {"none": 1/9,
                "lawn": 0.1,
                "pizza" : 1,
                "dutchman" : 1
                }
if(verbose){
  display("cns:" + CAUSAL_NETS)
  display("bias: " + BIAS)
  display("# tables:" + tables_list.length)
}


// Helper --------------------------------------------------------------------
var negate = function(x){
  return x.startsWith("-") ? x.slice(1) : "-" + x
}

var intersect_arrays = cache(function(arrays){
  return filter(function(m){
          var m_in_all_lists = map(function(idx){arrays[idx].indexOf(m)!=-1},
                                  _.range(1, arrays.length))
          return sum(m_in_all_lists)==m_in_all_lists.length
    }, arrays[0])
},10000)

var combinations = Infer({model:function(){
  var bools = repeat(vars.length, flip)
  var tokens = mapIndexed(function(idx, b){
    b ? uniformDraw(vars[idx]) : ""
  }, bools)
  return filter(function(t){t.length>0}, tokens)
}}).support()
var combinations = filter(function(x){x.length > 0}, combinations)

var combine_pairs = function(connective){
  var pairs_list = mapIndexed(function(idx, tokens1){
    var arr = filter(function(tokens){
      all(function(x){
        tokens.indexOf(x)==-1 && tokens.indexOf(negate(x)) == -1
      }, tokens1)
    }, combinations.slice(idx+1))

    var antecedent = tokens1.join(" and ")
    var ifs = map(function(tokens2){
      antecedent + connective + tokens2.join(" and ")
    }, arr)

    var ifs_rev = map(function(tokens2){
      tokens2.join(" and ") + connective + antecedent
    }, arr)
    return ifs.concat(ifs_rev)
  }, combinations)

  var pairs = reduce(function(arr, acc){
    acc.concat(arr)
  }, [], pairs_list)
  return pairs
}

// Probabilities ------------------------------------------------------------
var marginal = cache(function(table, variables){
  // computes the probability of marginalization over all variables for table
  // args: table: categorical distribution; ps:[..] and vs:["AC", "A-C", ..]
  //       variables: list; ["A"]
  var tokens = table.support()
  var all_x = map(function(v){
    v.includes("-") ? filter(function(k){k.includes(v)}, tokens) :
                      filter(function(k){!k.includes("-"+v)}, tokens)
  }, variables)
  var xs = intersect_arrays(all_x)

  return reduce(function(x, acc){acc + Math.exp(table.score(x))}, 0, xs)
})

var conditional_probs = cache(function(table){
  return {"P(C|A)" : marginal(table, ["A", "C"]) / marginal(table, ["A"]),
          "P(C|-A)": marginal(table, ["-A", "C"]) / marginal(table, ["-A"]),
          "P(A|C)" : marginal(table, ["A", "C"]) / marginal(table, ["C"]),
          "P(A|-C)": marginal(table, ["A", "-C"]) / marginal(table, ["-C"])}
}, 10000)

var cn_to_prob = cache(function(state){
  var cn = state.cn
  var table = state.table
  var probs = conditional_probs(table)
  return cn == "A implies C" ? [probs["P(C|A)"], probs["P(C|-A)"]] :
         cn == "A implies -C" ? [1 - probs["P(C|A)"], 1 - probs["P(C|-A)"]] :
         cn == "-A implies C" ? [probs["P(C|-A)"], probs["P(C|A)"]] :
         cn == "-A implies -C" ? [1 - probs["P(C|-A)"], 1 - probs["P(C|A)"]] :
         cn == "C implies A" ? [probs["P(A|C)"], probs["P(A|-C)"]] :
         cn == "C implies -A" ? [1 - probs["P(A|C)"], 1 - probs["P(A|-C)"]] :
         cn == "-C implies A" ? [probs["P(A|-C)"], probs["P(A|C)"]] :
         cn == "-C implies -A" ? [1 - probs["P(A|-C)"], 1 - probs["P(A|C)"]] :
         cn == "A || C" ? [marginal(table, ["A"]), marginal(table, ["C"]),
                           marginal(table, ["A", "C"])] :
  error('unknown network: ' + cn)
}, 10000)

// State prior  --------------------------------------------------------------
var cn_prior = function(bias) {
  var p_ind = p_ac_ind[bias]
  var p_dep = (1 - p_ind) / (CAUSAL_NETS.length-1)
  var ps = map(function(cn){cn=="A || C" ?  p_ind : p_dep}, CAUSAL_NETS)
  return categorical({vs: CAUSAL_NETS, ps: ps})
}

var log_likelihood = function(state){
  var p = cn_to_prob(state)
  return state.cn == "A || C" ?
          Gaussian({mu:p[0]*p[1], sigma:SIGMA}).score(p[2]) :
          (Beta({a:PARAM_NOR_THETA, b:1}).score(p[0]) +
           Beta({a:1, b:PARAM_NOR_BETA}).score(p[1]))
}

var state_prior = cache(function(bias){
  var distr = Infer({method:'enumerate', model:function(){
    var state = {"table": uniformDraw(TABLES),
                 "cn": cn_prior(bias)}
    factor(log_likelihood(state))

    if(bias=='lawn'){
      condition(Math.exp(state.table.score("-AC")) <= threshold_cp)
      //soft version:
      // if(Math.exp(state.table.score("-AC")) <= threshold_cp){
      //   factor(-Math.log(thresholds.f))
      // }
    } else if(bias=="pizza"){
      condition(state.cn == "A || C")
    } else if(bias == "dutchman"){
      condition(state.cn == "A || C" &&
                marginal(state.table, ["C"]) <= thresholds.f)
    }
    return state
  }})

  // make sure that states that have almost 0-probability are excldued,
  // otherwise these states face a problem for the speaker who cannot say
  // anything because the log of the literal listener will always be -Infinity
  return Infer({model:function(){
    var s = sample(distr)
    condition(Math.exp(distr.score(s)) > 0.0000011)
    return s
  }})
})

var all_states = state_prior(BIAS).support()
if(verbose){ display('# states: ' + all_states.length)}

// Utterances and meaning ----------------------------------------------------
var literals_conjunctions = map(function(tokens){
  tokens.join(" and ")
}, combinations)
var literals = filter(function(utt){!utt.includes(" and ")},
                      literals_conjunctions)
var likelys = map(function(utt){'likely ' + utt}, literals)
var conditionals = combine_pairs(" > ")

var utterances = literals_conjunctions.concat(conditionals.concat(likelys))

if(verbose){
  display('# literals + conjunctions: ' + literals_conjunctions.length)
  display('# conditionals: ' + conditionals.length)
  display('# likely: ' + likelys.length)
  display('' + '# all utterances: ' + utterances.length)
}

var utterance_probs = cache(function(utterance, table){
  if(utterance.includes(">")){
    var components = utterance.split(" > ")
    var antecedent = components[0].split(" and ").join("")
    var consequent = components[1].split(" and ").join("")
    return marginal(table, [antecedent, consequent]) /
           marginal(table, [antecedent])
  }
  else if(utterance.includes("likely")){
    var u = utterance.slice("likely ".length)
    return marginal(table, [u])
  }
  else if(utterance.includes("and")){
    var components = utterance.split(" and ")
    return marginal(table, components)
  }
  else {
    return marginal(table, [utterance])
  }
})

var meaning = cache(function(utterance, table){
 var p = utterance_probs(utterance, table)
 var u_applicable = utterance.includes('likely') ?
     (p >= thresholds.theta_likely) : p >= thresholds.theta
 return u_applicable
})

var utts_to_remove = filter(function(u){
  !any(function(s){meaning(u, s.table)}, all_states)
}, utterances)

var utterances = filter(function(u){utts_to_remove.indexOf(u)==-1}, utterances)
if(verbose){
  display("included utterances:")
  map(display, utterances)
  display('# included utterances: ' + utterances.length)

  display("")
  display('# utts without corresponding state: ' + utts_to_remove.length)
  display("removed utterances:")
  map(display, utts_to_remove)
}

utterances
